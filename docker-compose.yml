version: "3"
services:
  spark-job-service:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./Local_data:/app/Local_Data/Product
      - ./Delta_Table:/app/Delta_Table
      - ./spark_history_logs:/app/spark_history_logs

    environment:
      - SPARK_MASTER=local[*]

  spark-history-server:
    image: rangareddy1988/spark-history-server:${VERSION:-latest}
    container_name: spark-history-server
    command:
      - "/sbin/tini"
      - "-s"
      - "--"
      - "/opt/spark/bin/spark-class"
      - "-Dspark.history.fs.logDirectory=/app/spark_history_logs"
      - "org.apache.spark.deploy.history.HistoryServer"
    volumes:
      - ./spark_history_logs:/app/spark_history_logs
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/app/spark_history_logs -Dspark.history.ui.port=18080 -Dspark.history.retainedApplications=50 -Dspark.ui.retainedJobs=50 -Dspark.ui.retainedStages=50 -Dspark.ui.retainedTasks=50 -Dspark.worker.ui.retainedExecutors=50 -Dspark.worker.ui.retainedDrivers=50 -Dspark.sql.ui.retainedExecutions=50 -Dspark.streaming.ui.retainedBatches=50 -Dspark.history.ui.showIncomplete=true